{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolution Neural Network\n",
    "\n",
    "\n",
    "we can think of a CNN as an artificial neural network that has some type of specialization for being able to pick out or detect patterns. This pattern detection is what makes CNNs so useful for image analysis.\n",
    "\n",
    "CNNs have hidden layers called __convolutional layers__, and these layers are what make a CNN, well... a CNN!\n",
    "\n",
    "### Convolutional layers\n",
    "\n",
    "Just like any other layer, a convolutional layer receives input, transforms the input in some way, and then outputs the transformed input to the next layer. The inputs to convolutional layers are called input channels, and the outputs are called output channels.\n",
    "\n",
    "With a convolutional layer, the transformation that occurs is called a convolution operation. This is the term that’s used by the deep learning community anyway. Mathematically, the convolution operations performed by convolutional layers are actually called __cross-correlations__.\n",
    "\n",
    "cross-correlation is a measure of similarity of two series as a function of the displacement of one relative to the other. This is also known as a sliding dot product or sliding inner-product. It is commonly used for searching a long signal for a shorter, known feature. It has applications in pattern recognition, single particle analysis, electron tomography, averaging, cryptanalysis, and neurophysiology.\n",
    "\n",
    "\n",
    "#### Filters and convolution operations\n",
    "\n",
    "As mentioned earlier, convolutional neural networks are able to detect patterns in images. With each convolutional layer, we need to specify the number of filters the layer should have. These filters are actually what detect the patterns.\n",
    "\n",
    "##### Patterns\n",
    "\n",
    "Let's expand on precisely what we mean When we say that the filters are able to detect patterns. Think about how much may be going on in any single image. Multiple edges, shapes, textures, objects, etc. These are what we mean by patterns.\n",
    "\n",
    "- edges\n",
    "- shapes\n",
    "- textures\n",
    "- curves\n",
    "- objects\n",
    "- colors\n",
    "\n",
    "One type of pattern that a filter can detect in an image is edges, so this filter would be called an edge detector.\n",
    "\n",
    "Aside from edges, some filters may detect corners. Some may detect circles. Others, squares. Now these simple, and kind of geometric, filters are what we’d see at the start of a convolutional neural network.\n",
    "\n",
    "The deeper the network goes, the more sophisticated the filters become. In later layers, rather than edges and simple shapes, our filters may be able to detect specific objects like eyes, ears, hair or fur, feathers, scales, and beaks.\n",
    "\n",
    "In even deeper layers, the filters are able to detect even more sophisticated objects like full dogs, cats, lizards, and birds.\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filters (pattern detectors)\n",
    "\n",
    "To understand what’s actually happening here with these convolutional layers and their respective filters, let’s look at an example.\n",
    "\n",
    "Suppose we have a convolutional neural network that is accepting images of handwritten digits (like from the MNIST data set) and our network is classifying them into their respective categories of whether the image is of a 1, 2, 3, etc.\n",
    "\n",
    "![image.png](./Images/mnist.png)\n",
    "\n",
    "Let’s now assume that the first hidden layer in our model is a convolutional layer. As mentioned earlier, when adding a convolutional layer to a model, we also have to specify how many filters we want the layer to have.\n",
    "\n",
    "_The number of filters determine the number of output channels._\n",
    "\n",
    "A filter can technically just be thought of as a relatively small matrix ( tensor), for which, we decide the number of rows and columns this matrix has, and the values within this matrix are initialized with random numbers.\n",
    "\n",
    "For this first convolutional layer of ours, we’re going to specify that we want the layer to contain one filter of size 3 x 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Convolutional layer__\n",
    "\n",
    "Let’s look at an example animation of the convolution operation:\n",
    "\n",
    "![convolution](./Images/conv_op_same_padding_no_strides.gif \"Convolution\")\n",
    "\n",
    "This animation showcases the convolution process without numbers. We have an input channel in blue on the bottom. A convolutional filter shaded on the bottom that is sliding across the input channel, and a green output channel:\n",
    "\n",
    "1. Blue (bottom) - Input channel\n",
    "2. Shaded (on top of blue) - 3 x 3 convolutional filter\n",
    "3. Green (top) - Output channel\n",
    "\n",
    "For each position on the blue input channel, the 3 x 3 filter does a computation that maps the shaded part of the blue input channel to the corresponding shaded part of the green output channel.\n",
    "\n",
    "This convolutional layer receives an input channel, and the filter will slide over each 3 x 3 set of pixels of the input itself until it’s slid over every 3 x 3 block of pixels from the entire image.\n",
    "\n",
    "__Convolution operation__\n",
    "\n",
    "This sliding is referred to as _convolving_, so really, we should say that this filter is going to convolve across each 3 x 3 block of pixels from the input.\n",
    "\n",
    "The blue input channel is a matrix representation of an image from the MNIST dataset. The values in this matrix are the individual pixels from the image. These images are grayscale images, and so we only have a single input channel.\n",
    "\n",
    "- Grayscale images have a single color channel\n",
    "- RGB images have three color channels\n",
    "\n",
    "This input will be passed to a convolutional layer.\n",
    "\n",
    "As just discussed, we’ve specified the first convolutional layer to only have one filter, and this filter is going to convolve across each 3 x 3 block of pixels from the input. When the filter lands on its first 3 x 3 block of pixels, the dot product of the filter itself with the 3 x 3 block of pixels from the input will be computed and stored. This will occur for each 3 x 3 block of pixels that the filter convolves.\n",
    "\n",
    "For example, we take the dot product of the filter with the first 3 x 3 block of pixels, and then that result is stored in the output channel. Then, the filter slides to the next 3 x 3 block, computes the dot product, and stores the value as the next pixel in the output channel.\n",
    "\n",
    "After this filter has convolved the entire input, we’ll be left with a new representation of our input, which is now stored in the output channel. This output channel is called a __feature map__.\n",
    "\n",
    "This green output channel becomes the input channel to the next layer as input, and then this process that we just went through with the filter will happen to this new output channel with the next layer’s filters.\n",
    "\n",
    "This was just a very simple illustration, but as mentioned earlier, we can think of these filters as pattern detectors."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input and output channels\n",
    "\n",
    "Suppose that this grayscale image (single color channel) of a seven from the MNIST data set is our input:\n",
    "\n",
    "![image.png](./Images/mnist_7.png)\n",
    "\n",
    "Let’s suppose that we have four 3 x 3 filters for our first convolutional layer, and these filters are filled with the values you see below. These values can be represented visually by having -1s correspond to black, 1s correspond to white, and 0s correspond to grey."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ![image.jpg](./Images/conv_layers_filters.jpg)\n",
    " \n",
    "<center><i>Convolutional Layer with 4 filters</i></center>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we convolve our original image of a seven with each of these four filters individually, this is what the output would look like for each filter:\n",
    "\n",
    "![image.png](./Images/conv_out_chanl.png)\n",
    "\n",
    "<center><i>Output channels from the Convolutional Layer<i></center>\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that all four of these filters are detecting edges. In the output channels, the brightest pixels can be interpreted as what the filter has detected. In the first one, we can see detects top horizontal edges of the seven, and that’s indicated by the brightest pixels (white).\n",
    "\n",
    "The second detects left vertical edges, again being displayed with the brightest pixels. The third detects bottom horizontal edges, and the fourth detects right vertical edges.\n",
    "\n",
    "These filters, as we mentioned before, are really basic and just detect edges. These are filters we may see towards the start of a convolutional neural network. More complex filters would be located deeper in the network and would gradually be able to detect more sophisticated patterns like the ones shown here:\n",
    "\n",
    "![image.png](./Images/conv_layer2.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see the shapes that the filters on the left detected from the images on the right. We can see circles, curves and corners. As we go further into our layers, the filters are able to detect much more complex patterns like dog faces or bird legs shown here:\n",
    "\n",
    "![image.png](./Images/conv_layer4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The amazing thing is that the pattern detectors are derived automatically by the network. The filter values start out with random values, and the values change as the network learns during training. The pattern detecting capability of the filters emerges automatically.\n",
    "\n",
    "In the past, computer vision experts would develop filters (pattern detectors) manually. One example of this is the Sobel filter, an edge detector. However, with deep learning, we can learn these filters automatically using neural networks!\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
