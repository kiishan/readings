{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coding Artificial Neural Network\n",
    "\n",
    "https://towardsdatascience.com/how-to-build-your-own-neural-network-from-scratch-in-python-68998a08e4f6\n",
    "https://www.analyticsvidhya.com/blog/2017/05/neural-network-from-scratch-in-python-and-r/\n",
    "\n",
    "\n",
    "A neural Network Consists of Following Components:\n",
    "\n",
    "1. An input layer, x\n",
    "2. An arbitrary amount of hidden layers\n",
    "3. An output layer, ŷ\n",
    "4. A set of weights and biases between each layer, W and b\n",
    "5. A choice of activation function for each hidden layer, σ.\n",
    "6. Optimization funtion\n",
    "\n",
    "\n",
    "to Code a neural networks we have to code all these components\n",
    "\n",
    "let's start by creating a Neural Network class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coding ANN from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class NeuralNetwork:\n",
    "    def __init__(self, x, y):\n",
    "        self.input      = x\n",
    "        self.weights1   = np.random.rand(self.input.shape[1],4) # depend on num of input features \n",
    "        self.weights2   = np.random.rand(4,1)                 \n",
    "        self.y          = y\n",
    "        self.output     = np.zeros(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def feedforward(self):\n",
    "        self.layer1 = sigmoid(np.dot(self.input, self.weights1))\n",
    "        self.output = sigmoid(np.dot(self.layer1, self.weights2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    def backprop(self):\n",
    "        # application of the chain rule to find derivative of the loss function with respect to weights2 and weights1\n",
    "        d_weights2 = np.dot(self.layer1.T, (2*(self.y - self.output) * sigmoid_derivative(self.output)))\n",
    "        d_weights1 = np.dot(self.input.T,  (np.dot(2*(self.y - self.output) * sigmoid_derivative(self.output), self.weights2.T) * sigmoid_derivative(self.layer1)))\n",
    "\n",
    "        # update the weights with the derivative (slope) of the loss function\n",
    "        self.weights1 += d_weights1\n",
    "        self.weights2 += d_weights2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coding ANN\n",
    "\n",
    "https://stackabuse.com/creating-a-neural-network-from-scratch-in-python/\n",
    "\n",
    "Suppose we have some information about obesity, smoking habits, and exercise habits of five people. We also know whether these people are diabetic or not. Our dataset looks like this:\n",
    "\n",
    "|Person\t |Smoking |Obesity |Exercise|Diabetic|\n",
    "|--------|-------:|-------:|-------:|-------:|\n",
    "|Person 1|\t     0|\t      1|\t   0|\t    1|\n",
    "|Person 2|\t     0|       0|\t   1|\t    0|\n",
    "|Person 3|\t     1|\t      0|\t   0|\t    0|\n",
    "|Person 4|\t     1|       1|\t   0|\t    1|\n",
    "|Person 5|\t     1|\t      1|\t   1|\t    1|\n",
    "\n",
    "In the above table, we have five columns: Person, Smoking, Obesity, Exercise, and Diabetic. Here 1 refers to true and 0 refers to false. For instance, the first person has values of 0, 1, 0 which means that the person doesn't smoke, is obese, and doesn't exercise. The person is also diabetic.\n",
    "\n",
    "It is clearly evident from the dataset that a person's obesity is indicative of him being diabetic. Our task is to create a neural network that is able to predict whether an unknown person is diabetic or not given data about his exercise habits, obesity, and smoking habits. This is a type of supervised learning problem where we are given inputs and corresponding correct outputs and our task is to find the mapping between the inputs and the outputs.\n",
    "\n",
    "Note: This is just a fictional dataset, in real life, obese people are not necessarily always diabetic.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Taking input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np  \n",
    "\n",
    "feature_set = np.array([[0,1,0],[0,0,1],[1,0,0],[1,1,0],[1,1,1]])      # input feature\n",
    "labels = np.array([[1,0,0,1,1]]).reshape(5,1)                          # results\n",
    "\n",
    "feature_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining Hyper parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)               # random.seed function returns the same random values whenever the script is executed.\n",
    "\n",
    "weights = np.random.rand(3,1)    # generate random nummbers for weights 3 rows 1 colm, for 3 input features\n",
    "bias = np.random.rand(1)         # only 1 bias, as this is a single layer perceptron moldel only one neuron is there\n",
    "lr = 0.05                        # controls how much we are adjusting the weights of our network with respect the loss gradient.\n",
    "epoch = 2000\n",
    "\n",
    "def sigmoid(x):                  # Activation function\n",
    "    return 1/(1+np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid_der(x):                    # Derivative of Activation func to do backpropagation and adjust weights\n",
    "    return sigmoid(x)*(1-sigmoid(x))   # The derivative of sigmoid function is simply sigmoid(x) * sigmoid(1-x)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for iter in range(epoch):  \n",
    "    \n",
    "    inputs = feature_set\n",
    "    \n",
    "    XW = np.dot(feature_set, weights) + bias       # feedforward step1\n",
    "                                                   # find dot product of input and weight vector and add bias to it.\n",
    "        \n",
    "    z = sigmoid(XW)                                # feedforward step2\n",
    "                                                   # variable z contains the predicted outputs.\n",
    "        \n",
    "    error = z - labels                             # backpropagation step 1\n",
    "    #print(error.sum())                             # Calculating error for backpropagation\n",
    "    \n",
    "    dcost_dpred = error                            # backpropagation step 2\n",
    "    dpred_dz = sigmoid_der(z)\n",
    "\n",
    "    z_delta = dcost_dpred * dpred_dz\n",
    "\n",
    "    inputs = feature_set.T\n",
    "    weights -= lr * np.dot(inputs, z_delta)\n",
    "\n",
    "    for num in z_delta:\n",
    "        bias -= lr * num"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Training the model has basically predicted the best possible weight and bias value for which the equation can give the nearly correct output for set of input feature__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_point = np.array([1,0,0])  \n",
    "result = sigmoid(np.dot(single_point, weights) + bias)  \n",
    "print(result) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_point = np.array([0,1,0])  \n",
    "result = sigmoid(np.dot(single_point, weights) + bias)  \n",
    "print(result) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coding ANN for classification problems (Iris)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape (120, 4)\n",
      "X_test shape (30, 4)\n",
      "y_train shape (120, 1)\n",
      "y_test shape (30, 1)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "data = pd.read_csv('./data/Iris.csv')\n",
    "\n",
    "#Convert the Species labels to indexes for use with neural network.\n",
    "target = data[['Species']].replace(['Iris-setosa','Iris-versicolor','Iris-virginica'],[0,1,2])\n",
    "\n",
    "# Normalize the data\n",
    "data = data[['SepalLengthCm', 'SepalWidthCm', 'PetalLengthCm', 'PetalWidthCm']].apply(lambda x: (x - x.min()) / (x.max() - x.min()))\n",
    "\n",
    "# finalized data\n",
    "data = pd.concat([data, target], axis=1)\n",
    "\n",
    "# splitting data to train test\n",
    "X = data[['SepalLengthCm', 'SepalWidthCm', 'PetalLengthCm', 'PetalWidthCm']]\n",
    "y = data[['Species']]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.20, random_state=42)\n",
    "\n",
    "print('X_train shape', X_train.shape)\n",
    "print('X_test shape', X_test.shape)\n",
    "print('y_train shape', y_train.shape)\n",
    "print('y_test shape', y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining Hyper Parameters\n",
    "\n",
    "we will be desiging a 3 layer architechure\n",
    "\n",
    "1. Input layer : contains 4 nodes\n",
    "2. Hidden layer: contains 5 nodes\n",
    "3. Output layer: contains 3 nodes\n",
    "\n",
    "we need to define\n",
    "\n",
    "1. weights for layer 1 -> layer 2, size[4,5]\n",
    "2. weights for layer 3 -> layer 3, size[5,3]\n",
    "\n",
    "3. bias for layer 1 -> layer 2, size[5,1] 5 nodes in layer 2\n",
    "4. bias for layer 3 -> layer 3, size[3,1] 3 nodes in layer 3\n",
    "\n",
    "5. epoch\n",
    "6. learining rate\n",
    "\n",
    "7. feed forward mechanism (activation function)\n",
    "8. backpropagation mechanism (cost function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_inputs = len(X[0])\n",
    "hidden_layer_neurons = 5\n",
    "np.random.seed(4)\n",
    "\n",
    "\n",
    "\n",
    "weight_1 = np.random.random((4, 5))\n",
    "weight_2 = np.random.random((5, 3))\n",
    "\n",
    "'''\n",
    "bias_1 = np.random.random((5, 1))\n",
    "bias_2 = np.random.random((3, 1))\n",
    "'''\n",
    "epoch = 10000\n",
    "learning_rate = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):                  # Activation function\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "def sigmoid_der(x):                    # Derivative of Activation func to do backpropagation and adjust weights\n",
    "    return sigmoid(x)*(1-sigmoid(x))   # The derivative of sigmoid function is simply sigmoid(x) * sigmoid(1-x)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(120, 5)\n",
      "(120, 3)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Unable to coerce to DataFrame, shape must be (120, 1): given (120, 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-960b19019d25>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ml2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[0mer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mabs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0ml2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m     \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     '''\n",
      "\u001b[1;32mc:\\users\\kishan.kumar\\appdata\\local\\continuum\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\pandas\\core\\ops.py\u001b[0m in \u001b[0;36mf\u001b[1;34m(self, other, axis, level, fill_value)\u001b[0m\n\u001b[0;32m   1545\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdefault_axis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1546\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1547\u001b[1;33m         \u001b[0mother\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_align_method_FRAME\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1548\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1549\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mABCDataFrame\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# Another DataFrame\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\kishan.kumar\\appdata\\local\\continuum\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\pandas\\core\\ops.py\u001b[0m in \u001b[0;36m_align_method_FRAME\u001b[1;34m(left, right, axis)\u001b[0m\n\u001b[0;32m   1468\u001b[0m                                  \u001b[1;34m\"must be {req_shape}: given {given_shape}\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1469\u001b[0m                                  .format(req_shape=left.shape,\n\u001b[1;32m-> 1470\u001b[1;33m                                          given_shape=right.shape))\n\u001b[0m\u001b[0;32m   1471\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1472\u001b[0m             right = left._constructor(right, index=left.index,\n",
      "\u001b[1;31mValueError\u001b[0m: Unable to coerce to DataFrame, shape must be (120, 1): given (120, 3)"
     ]
    }
   ],
   "source": [
    "for iter in range(epoch):  \n",
    "    \n",
    "    inputs = X_train\n",
    "    \n",
    "    l1 = 1/(1 + np.exp(-(np.dot(X_train, weight_1)))) # sigmoid function\n",
    "    l2 = 1/(1 + np.exp(-(np.dot(l1, weight_2))))\n",
    "    print(l1.shape)\n",
    "    print(l2.shape)\n",
    "    \n",
    "    er = (abs(y_train - l2)).mean()\n",
    "    break\n",
    "    '''\n",
    "    l2_delta = (y - l2)*(l2 * (1-l2))\n",
    "    l1_delta = l2_delta.dot(weight_2.T) * (l1 * (1-l1))\n",
    "    \n",
    "    weight_2 += l1.T.dot(l2_delta) * learning_rate\n",
    "    weight_1 += X_train.T.dot(l1_delta) * learning_rate\n",
    "    \n",
    "print('Error:', er)'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coding ANN in Tensorflow & Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
